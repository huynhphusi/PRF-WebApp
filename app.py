import streamlit as st
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.figure_factory as ff
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.impute import SimpleImputer
from xgboost import XGBClassifier
from sklearn.model_selection import KFold   # DÃ¹ng Ä‘á»ƒ táº¡o py
from PRF import prf

from utils import display_dataframe_info, auto_clean, estimate_noise_level

st.set_page_config(page_title="á»¨ng dá»¥ng ML", layout="wide")
st.title("ğŸ¤– á»¨ng dá»¥ng ML trá»±c quan tá»« CSV")
st.markdown("""
    ### HÆ°á»›ng dáº«n sá»­ dá»¥ng
    1. Táº£i lÃªn file CSV chá»©a dá»¯ liá»‡u cá»§a báº¡n.
    2. Chá»n cá»™t má»¥c tiÃªu (target) Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh.
    3. Lá»±a chá»n mÃ´ hÃ¬nh vÃ  nháº¥n "Train mÃ´ hÃ¬nh" Ä‘á»ƒ báº¯t Ä‘áº§u huáº¥n luyá»‡n.
    4. Táº£i lÃªn file CSV má»›i Ä‘á»ƒ dá»± Ä‘oÃ¡n káº¿t quáº£.
""")
st.markdown("""
<style>
.stButton>button {
    background-color: #4CAF50;
    color: white;
}
</style>
""", unsafe_allow_html=True)

# Upload CSV
ordinary_file = st.file_uploader("ğŸ“ Táº£i lÃªn file CSV", type=["csv"])

if ordinary_file:
    # Check if a new file is uploaded or if the file has changed
    if "ordinary_filename" not in st.session_state or ordinary_file.name != st.session_state["ordinary_filename"]:
        df = pd.read_csv(ordinary_file)
        if len(df) > 100000:
            st.warning("Dá»¯ liá»‡u lá»›n (>100,000 dÃ²ng). á»¨ng dá»¥ng sáº½ láº¥y máº«u ngáº«u nhiÃªn 100,000 dÃ²ng Ä‘á»ƒ xá»­ lÃ½.")
            df = df.sample(n=100000, random_state=42)
        st.session_state["ordinary_df"] = df
        st.session_state["ordinary_filename"] = ordinary_file.name
        # Clear previous training results when a new dataset is uploaded
        if "trained_model" in st.session_state:
            del st.session_state["trained_model"]
            del st.session_state["X_test"]
            del st.session_state["y_test"]
            del st.session_state["X_train"]
            del st.session_state["y_train"]
            del st.session_state["model_name"]
            del st.session_state["feature_names"]
            del st.session_state["col_target"]

# Láº¥y dá»¯ liá»‡u tá»« session_state Ä‘á»ƒ dÃ¹ng
if "ordinary_df" in st.session_state:
    df = st.session_state["ordinary_df"]
else:
    st.warning("âš ï¸ Vui lÃ²ng táº£i lÃªn má»™t file CSV Ä‘á»ƒ báº¯t Ä‘áº§u.")
    st.stop()

st.subheader("ğŸ“Š Dá»¯ liá»‡u Ä‘Ã£ táº£i lÃªn:")
st.dataframe(df.head())

st.subheader("ğŸ“Œ Thá»‘ng kÃª dá»¯ liá»‡u sá»‘:")
st.write(df.describe())

st.subheader("ğŸ“Œ Thá»‘ng kÃª kiá»ƒu dá»¯ liá»‡u:")

st.dataframe(display_dataframe_info(df))

# Biá»ƒu Ä‘á»“ trÃ²n (dÃ¹ng cáº£ cá»™t sá»‘ rá»i ráº¡c)
st.subheader("ğŸ¥§ Biá»ƒu Ä‘á»“ trÃ²n (cho cá»™t rá»i ráº¡c):")

# Chá»n cÃ¡c cá»™t cÃ³ < 20 giÃ¡ trá»‹ duy nháº¥t
discrete_cols = [col for col in df.columns if df[col].nunique() < 20]

if discrete_cols:
    pie_col = st.selectbox("Chá»n cá»™t rá»i ráº¡c:", discrete_cols, key="pie")
    pie_data = df[pie_col].value_counts().reset_index()
    pie_data.columns = [pie_col, 'count']
    fig_pie = px.pie(pie_data, values='count', names=pie_col, title=f"PhÃ¢n bá»‘ giÃ¡ trá»‹ trong '{pie_col}'")
    st.plotly_chart(fig_pie)
else:
    st.info("KhÃ´ng cÃ³ cá»™t rá»i ráº¡c Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“ trÃ²n.")

st.subheader("ğŸ“Š LÃ m sáº¡ch dá»¯ liá»‡u:")
col_target = st.selectbox("Cá»™t má»¥c tiÃªu (target):", df.columns)
if col_target and col_target != df.columns[0]:
    col_target = col_target.strip().lower().replace(' ', '_')
    df_prf = auto_clean(df, target_col=col_target)

    df_cleaned = df_prf.copy()
    imputer = SimpleImputer(strategy='median')
    X_imputed = imputer.fit_transform(df_cleaned.drop(columns=col_target))
    st.session_state['imputer'] = imputer # LÆ°u láº¡i imputer
    df_noprf = pd.DataFrame(X_imputed, columns=df_cleaned.columns[:-1])
    df_noprf[col_target] = df_cleaned[col_target].values

    st.session_state["df_prf"] = df_prf
    st.session_state["df_noprf"] = df_noprf
    st.session_state["col_target"] = col_target

if "col_target" in st.session_state:
    col_target = st.session_state["col_target"]
if "df_prf" in st.session_state:
    df_prf = st.session_state["df_prf"]
if "df_noprf" in st.session_state:
    df_noprf = st.session_state["df_noprf"]

    st.dataframe(df_noprf.head())

    st.subheader("ğŸ§  Huáº¥n luyá»‡n dá»¯ liá»‡u:")
    model_name = st.selectbox("ğŸ§  Chá»n mÃ´ hÃ¬nh:", ["Random Forest", "SVM", "XGBoost", "Probabilistic Random Forest"])

    # Train mÃ´ hÃ¬nh button
    if st.button("ğŸš€ Train mÃ´ hÃ¬nh"):
        X = df_noprf.drop(columns=[col_target])
        y = df_noprf[col_target]
        
        # Kiá»ƒm tra náº¿u X vÃ  y cÃ³ sá»‘ lÆ°á»£ng máº«u phÃ¹ há»£p
        if len(X) != len(y):
            st.error("Sá»‘ lÆ°á»£ng hÃ ng trong features (X) vÃ  target (y) khÃ´ng khá»›p. Vui lÃ²ng kiá»ƒm tra láº¡i dá»¯ liá»‡u CSV vÃ  cá»™t má»¥c tiÃªu.")
            st.stop()
        
        # Kiá»ƒm tra náº¿u y cÃ³ nhiá»u hÆ¡n 1 lá»›p cho phÃ¢n loáº¡i
        if y.nunique() < 2:
            st.error("Cá»™t má»¥c tiÃªu chá»‰ cÃ³ má»™t hoáº·c khÃ´ng cÃ³ giÃ¡ trá»‹ duy nháº¥t. KhÃ´ng thá»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh phÃ¢n loáº¡i.")
            st.stop()


        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        if model_name == "Random Forest":
            model = RandomForestClassifier(n_estimators=100, max_depth=8, min_samples_split=10, random_state=42)
        elif model_name == "SVM":
            model = SVC(kernel='rbf', C=1.0, probability=True, random_state=42)
        elif model_name == "XGBoost":
            model = XGBClassifier(n_estimators=100, max_depth=8, min_child_weight=10, learning_rate=0.1, eval_metric='mlogloss', random_state=42)
        else:
            X_prf = df_prf.drop(columns=[col_target])  # Drop the target column for features
            y_prf = df_prf[col_target]
            X_prf = X_prf.values if isinstance(X_prf, pd.DataFrame) else X_prf
            y_prf = y_prf.values if isinstance(y_prf, pd.Series) else y_prf
            noise_level = estimate_noise_level(X_prf)
            dX = noise_level * np.abs(np.nan_to_num(X_prf, nan=1.0)) + 0.01
            kf = KFold(n_splits=5, shuffle=True, random_state=42)
            n_classes = len(np.unique(y_prf))
            py = np.zeros((len(X_prf), n_classes))

            for train_idx, val_idx in kf.split(X_prf):
                rf = RandomForestClassifier(n_estimators=50, max_depth=8, n_jobs=-1, random_state=41)
                rf.fit(X_prf[train_idx], y_prf[train_idx])
                py[val_idx] = rf.predict_proba(X_prf[val_idx])
            X_train, X_test, dX_train, dX_test, py_train, py_test = train_test_split(
                X_prf, dX, py, test_size=0.2, random_state=40, stratify=np.argmax(py, axis=1)
            )
            model = prf(n_estimators=100, bootstrap=True, max_depth=8, keep_proba=1.0, n_jobs=-1)

        try:
            with st.spinner("â³ Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh, vui lÃ²ng chá»..."):
                if model_name == "Probabilistic Random Forest":
                    model.fit(X=X_train, dX=dX_train, py=py_train)
                    st.session_state["noise_level"] = noise_level
                    st.session_state["dX_test"] = dX_test
                    st.session_state["py_test"] = py_test
                    st.session_state["dX_train"] = dX_train
                    st.session_state["py_train"] = py_train
                else:
                    model.fit(X_train, y_train)
                
            # âœ… LÆ°u model & dá»¯ liá»‡u vÃ o session_state
            st.session_state["trained_model"] = model
            st.session_state["X_test"] = X_test
            st.session_state["y_test"] = y_test
            st.session_state["X_train"] = X_train
            st.session_state["y_train"] = y_train
            st.session_state["model_name"] = model_name
            st.session_state["feature_names"] = X.columns.tolist() # Convert to list for session_state compatibility
            st.session_state["col_target"] = col_target

            st.success(f"âœ… MÃ´ hÃ¬nh **{model_name}** Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n!")
        except Exception as e:
            st.error(f"Lá»—i khi huáº¥n luyá»‡n mÃ´ hÃ¬nh: {e}")

    # --- Hiá»ƒn thá»‹ káº¿t quáº£ huáº¥n luyá»‡n (chá»‰ khi cÃ³ mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n) ---
    if "trained_model" in st.session_state:
        st.markdown("---")
        st.subheader("ğŸ“Š Káº¿t quáº£ huáº¥n luyá»‡n mÃ´ hÃ¬nh")

        model = st.session_state["trained_model"]
        X_test = st.session_state["X_test"]
        y_test = st.session_state["y_test"]
        model_name = st.session_state["model_name"]
        col_target = st.session_state["col_target"]
        feature_names = st.session_state["feature_names"]

        with st.spinner("â³ Äang Ä‘Ã¡nh giÃ¡ káº¿t quáº£ huáº¥n luyá»‡n, vui lÃ²ng chá»..."):
            if model_name == "Probabilistic Random Forest":
                noise_level = st.session_state["noise_level"]
                dX_test = st.session_state["dX_test"]
                py_test = st.session_state["py_test"]

                y_test = py_test.argmax(axis=1)
                y_proba_prf = np.array(model.predict_proba(X_test, dX=dX_test))
                y_pred = y_proba_prf.argmax(axis=1)
            else:
                y_pred = model.predict(X_test)

            st.text("ğŸ“„ Classification Report:")
            report = classification_report(y_test, y_pred, output_dict=True)
            report_df = pd.DataFrame(report).transpose()
            st.dataframe(report_df)

            st.text("ğŸ“‰ Confusion Matrix:")
            cm = confusion_matrix(y_test, y_pred)
            fig_cm = ff.create_annotated_heatmap(
                z=cm, x=list(map(str, range(cm.shape[1]))), y=list(map(str, range(cm.shape[0]))),
                annotation_text=cm, colorscale='Blues'
            )
            fig_cm.update_layout(xaxis_title="Dá»± Ä‘oÃ¡n", yaxis_title="Thá»±c táº¿")
            st.plotly_chart(fig_cm)
        
        # --- Pháº§n dá»± Ä‘oÃ¡n dá»¯ liá»‡u má»›i (chá»‰ khi cÃ³ mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n) ---
        st.markdown("---")
        st.header("ğŸš€ Dá»± Ä‘oÃ¡n vá»›i dá»¯ liá»‡u má»›i")

        st.subheader("ğŸ“¥ Táº£i lÃªn CSV má»›i Ä‘á»ƒ dá»± Ä‘oÃ¡n")
        predict_file = st.file_uploader("Táº£i lÃªn file CSV má»›i Ä‘á»ƒ dá»± Ä‘oÃ¡n", type=["csv"], key="predict")

        if predict_file:
            df_pre = pd.read_csv(predict_file)
            st.dataframe(df_pre)
            
            df_pre_prf = auto_clean(df_pre, target_col=col_target)

            df_cleaned = df_pre_prf.copy()
            if 'imputer' in st.session_state:
                imputer = st.session_state['imputer']
            X_imputed = imputer.transform(df_cleaned.drop(columns=col_target))
            df_pre_noprf = pd.DataFrame(X_imputed, columns=df_cleaned.columns[:-1])
            df_pre_noprf[col_target] = df_cleaned[col_target].values

            st.subheader("ğŸ“Š Dá»¯ liá»‡u Ä‘Ã£ lÃ m sáº¡ch:")
            st.dataframe(df_pre_noprf.head())

            # Kiá»ƒm tra xem cÃ¡c cá»™t cá»§a dá»¯ liá»‡u má»›i cÃ³ khá»›p vá»›i cÃ¡c cá»™t Ä‘Ã£ huáº¥n luyá»‡n khÃ´ng
            if not all(col in df_pre_noprf.columns[:-1].tolist() for col in feature_names):
                st.error("Tá»‡p CSV má»›i khÃ´ng chá»©a táº¥t cáº£ cÃ¡c cá»™t tÃ­nh nÄƒng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh. Vui lÃ²ng Ä‘áº£m báº£o cÃ¡c cá»™t khá»›p.")
            else:
                try:
                    if model_name == "Probabilistic Random Forest":
                        X_pre = df_pre_prf[feature_names]
                        X_pre = X_pre.values if isinstance(X_pre, pd.DataFrame) else X_pre
                        predictions = np.array(model.predict_proba(X_pre, dX=np.abs(X_pre) * noise_level + 0.01)).argmax(axis=1)
                    else:
                        X_pre = df_pre_noprf[feature_names]
                        predictions = model.predict(X_pre)
                    df_pre_noprf["Dá»± Ä‘oÃ¡n"] = predictions
                    
                    # If the model has predict_proba (like Logistic Regression, Random Forest, but not always SVM)
                    if hasattr(model, 'predict_proba'):
                        probabilities = np.array(model.predict_proba(X_pre))
                        # Get class labels
                        if model_name == "Probabilistic Random Forest":
                            class_labels = list(range(probabilities.shape[1]))  # GÃ¡n nhÃ£n lÃ  0,1,...n_classes-1
                        else:
                            class_labels = model.classes_
                        # Add probability columns
                        for i, label in enumerate(class_labels):
                            df_pre_noprf[f"XÃ¡c suáº¥t {label}"] = probabilities[:, i]

                    st.subheader("ğŸ“‹ Káº¿t quáº£ dá»± Ä‘oÃ¡n:")
                    st.dataframe(df_pre_noprf)
                    
                    csv = df_pre_noprf.to_csv(index=False).encode('utf-8')
                    st.download_button("ğŸ“¥ Táº£i káº¿t quáº£ CSV", data=csv, file_name="du_doan.csv", mime='text/csv')
                except Exception as e:
                    st.error(f"Lá»—i khi dá»± Ä‘oÃ¡n: {e}. Vui lÃ²ng kiá»ƒm tra Ä‘á»‹nh dáº¡ng dá»¯ liá»‡u vÃ  Ä‘áº£m báº£o cÃ¡c cá»™t sá»‘ khá»›p vá»›i dá»¯ liá»‡u huáº¥n luyá»‡n.")
    else:
        st.info("ğŸ’¡ Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c khi dá»± Ä‘oÃ¡n dá»¯ liá»‡u má»›i.")
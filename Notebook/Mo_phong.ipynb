{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1750051051137,
     "user": {
      "displayName": "Huỳnh Phú Sĩ",
      "userId": "14333305800252361705"
     },
     "user_tz": -420
    },
    "id": "GLNHLDm0FqnH",
    "outputId": "7b9539a7-f2d7-4486-efd8-d8a3231501e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] The system cannot find the path specified: '/content/drive/MyDrive/IT/Cao hoc/Luan van/Python/'\n",
      "d:\\My Drive\\IT\\Cao hoc\\Luan van\\Python\n"
     ]
    }
   ],
   "source": [
    "%cd \"/content/drive/MyDrive/IT/Cao hoc/Luan van/Python/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13607,
     "status": "ok",
     "timestamp": 1750051067804,
     "user": {
      "displayName": "Huỳnh Phú Sĩ",
      "userId": "14333305800252361705"
     },
     "user_tz": -420
    },
    "id": "IgTgRL2eG55G",
    "outputId": "a0452667-7ab7-4534-fd36-df5da9bf22bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /content/drive/MyDrive/IT/Cao hoc/Luan van/Python\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from PRF==0.1.dev0) (2.0.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from PRF==0.1.dev0) (1.15.3)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from PRF==0.1.dev0) (0.60.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from PRF==0.1.dev0) (1.5.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->PRF==0.1.dev0) (0.43.0)\n",
      "Building wheels for collected packages: PRF\n",
      "  Building wheel for PRF (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for PRF: filename=PRF-0.1.dev0-py3-none-any.whl size=13034 sha256=dcf51f1966d5a26cb8d33c5a6e9ca0a4b69067723b8deb2f181ee5b29b64319b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vf8883s3/wheels/55/72/3f/d04142653063b3553a2988a5f80f02eebc0ba3d4943780c56b\n",
      "Successfully built PRF\n",
      "Installing collected packages: PRF\n",
      "Successfully installed PRF-0.1.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3339,
     "status": "ok",
     "timestamp": 1750051206551,
     "user": {
      "displayName": "Huỳnh Phú Sĩ",
      "userId": "14333305800252361705"
     },
     "user_tz": -420
    },
    "id": "lXRbDgXsI_Ct"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, log_loss, brier_score_loss, recall_score, f1_score, precision_score, ConfusionMatrixDisplay, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold   # Dùng để tạo py\n",
    "from PRF import prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1750051209645,
     "user": {
      "displayName": "Huỳnh Phú Sĩ",
      "userId": "14333305800252361705"
     },
     "user_tz": -420
    },
    "id": "mZyS6BiGJGZ0"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def generate_noisy_dataset(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_classes=3,\n",
    "    weights=[0.5, 0.3, 0.2],\n",
    "    noise_level=0.1,\n",
    "    label_noise_ratio=0.3,\n",
    "    noise_type='uniform',\n",
    "    n_groups=2,\n",
    "    missing_rate=0.0,\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Tạo dữ liệu có nhiễu cho PRF theo 4 kiểu: uniform, per_feature, grouped, complex.\n",
    "\n",
    "    Trả về:\n",
    "        X: giá trị đặc trưng (n_samples x n_features)\n",
    "        dX: độ lệch chuẩn của đặc trưng (n_samples x n_features)\n",
    "        y: nhãn\n",
    "        py: xác suất nhãn (PMF) (n_samples x n_classes)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed=random_state)\n",
    "\n",
    "    # Tạo dữ liệu cơ bản\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        n_informative=int(0.6 * n_features),\n",
    "        n_redundant=int(0.2 * n_features),\n",
    "        n_classes=n_classes,\n",
    "        weights=weights,\n",
    "        flip_y=noise_level * label_noise_ratio,\n",
    "        class_sep=1.5 - noise_level,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Nhiễu đặc trưng (feature noise)\n",
    "    if noise_type == 'uniform':\n",
    "        # Mọi điểm dữ liệu đều có mức nhiễu giống nhau (ngay cả giữa các đặc trưng)\n",
    "        dX = np.full_like(X, fill_value=noise_level * np.std(X) + 0.01)\n",
    "\n",
    "    elif noise_type == 'per_feature':\n",
    "        # Mỗi đặc trưng (cột) có độ nhiễu khác nhau nhưng đồng đều trên tất cả các mẫu. Ví dụ: sensor A nhiễu hơn sensor B.\n",
    "        feature_noise = rng.uniform(0.5, 1.5, size=n_features)\n",
    "        dX = noise_level * np.abs(X) * feature_noise + 0.01\n",
    "\n",
    "    elif noise_type == 'grouped':\n",
    "        # Dữ liệu chia thành n nhóm, mỗi nhóm có pattern nhiễu khác nhau cho các đặc trưng. Ví dụ: mỗi thiết bị đo (hoặc survey) có sai số đặc trưng riêng.\n",
    "        group_size = n_samples // n_groups\n",
    "        dX = np.zeros_like(X)\n",
    "        for g in range(n_groups):\n",
    "            start = g * group_size\n",
    "            end = n_samples if g == n_groups - 1 else (g + 1) * group_size\n",
    "            group_noise = rng.uniform(0.5, 1.5, size=n_features)\n",
    "            dX[start:end] = noise_level * np.abs(X[start:end]) * group_noise + 0.01\n",
    "\n",
    "    elif noise_type == 'complex':\n",
    "        # Mức nhiễu thay đổi theo mỗi đặc trưng của từng mẫu, hoàn toàn không có mẫu số chung. Đây là mô hình thực tế nhất nhưng khó học nhất nếu không khai báo uncertainty.\n",
    "        object_noise = rng.uniform(0.5, 1.5, size=(n_samples, 1))\n",
    "        feature_noise = rng.uniform(0.5, 1.5, size=(1, n_features))\n",
    "        dX = noise_level * np.abs(X) * (object_noise @ feature_noise) + 0.01\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Không hỗ trợ noise_type = '{noise_type}'\")\n",
    "    \n",
    "    # Thêm nhiễu vào biến X\n",
    "    X = X + dX * rng.normal(size=X.shape)\n",
    "    \n",
    "    # Tạo dữ liệu bị miss (NaN) ngẫu nhiên\n",
    "    if missing_rate > 0.0:\n",
    "        total_values = n_samples * n_features\n",
    "        n_missing = int(total_values * missing_rate)\n",
    "\n",
    "        # Chọn ngẫu nhiên các chỉ số để đặt NaN\n",
    "        missing_indices = rng.choice(total_values, size=n_missing, replace=False)\n",
    "        row_indices = missing_indices // n_features\n",
    "        col_indices = missing_indices % n_features\n",
    "\n",
    "        X[row_indices, col_indices] = np.nan\n",
    "        dX[np.isnan(X)] = 1.0\n",
    "\n",
    "        imputer = SimpleImputer(strategy=\"mean\")  # hoặc 'median', 'most_frequent'\n",
    "        X = imputer.fit_transform(X)\n",
    "    \n",
    "    # Tạo py\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    py = np.zeros((len(X), n_classes))\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        rf = RandomForestClassifier(n_estimators=50, max_depth=8, n_jobs=-1, random_state=41)\n",
    "        rf.fit(X[train_idx], y[train_idx])\n",
    "        py[val_idx] = rf.predict_proba(X[val_idx])\n",
    "\n",
    "    return X, dX, y, py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "executionInfo": {
     "elapsed": 459,
     "status": "ok",
     "timestamp": 1750051212382,
     "user": {
      "displayName": "Huỳnh Phú Sĩ",
      "userId": "14333305800252361705"
     },
     "user_tz": -420
    },
    "id": "EuIg4r7lJcmD",
    "outputId": "511a234c-7a7a-4e1d-ed93-a022bda8c288"
   },
   "outputs": [],
   "source": [
    "noisy_type = 1  # Feature Noise\n",
    "#noisy_type = 2  # Label Noise\n",
    "#noisy_type  = 3  # Feature Noise + Label Noise\n",
    "n_samples = 100000\n",
    "noise_level = 0.1\n",
    "label_noise_ratio=0.1\n",
    "n_classes   = 2\n",
    "weights     = [0.6, 0.4]\n",
    "missing_rate=0.1\n",
    "\n",
    "if noisy_type==1:\n",
    "    X, dX, y, py = generate_noisy_dataset(\n",
    "        n_samples=n_samples,\n",
    "        n_features=20,\n",
    "        n_classes=n_classes,\n",
    "        weights=weights,\n",
    "        noise_type='uniform',   # đặc trưng nhiễu kiểu khó\n",
    "        label_noise_ratio=label_noise_ratio,  # giữ nhãn chính xác\n",
    "        noise_level=noise_level,         # % nhiễu\n",
    "        missing_rate = missing_rate\n",
    "    )\n",
    "elif noisy_type == 2:\n",
    "    X, dX, y, py = generate_noisy_dataset(\n",
    "        n_samples=n_samples,\n",
    "        n_features=20,\n",
    "        n_classes=n_classes,\n",
    "        weights=weights,\n",
    "        noise_type='uniform',   # giữ đặc trưng sạch\n",
    "        label_noise_ratio=label_noise_ratio,  # flip_y = noise_level * 1.0\n",
    "        noise_level=noise_level,         # % nhiễu\n",
    "        missing_rate = missing_rate\n",
    "    )\n",
    "else:\n",
    "    X, dX, y, py = generate_noisy_dataset(\n",
    "        n_samples=n_samples,\n",
    "        n_features=20,\n",
    "        n_classes=n_classes,\n",
    "        weights=weights,\n",
    "        noise_type='complex',   # đặc trưng nhiễu kiểu khó\n",
    "        label_noise_ratio=label_noise_ratio,\n",
    "        noise_level=noise_level,         # % nhiễu\n",
    "        missing_rate = missing_rate\n",
    "    )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34390,
     "status": "ok",
     "timestamp": 1750051251802,
     "user": {
      "displayName": "Huỳnh Phú Sĩ",
      "userId": "14333305800252361705"
     },
     "user_tz": -420
    },
    "id": "D9xzxWEPJjzL",
    "outputId": "d4f7baec-d44b-4365-f94c-02b901cd691f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy: 0.92\n",
      "RF F1 Score: 0.91\n",
      "RF Log Loss: 0.2577\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=100, max_depth=8, min_samples_split=10, random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_rf.predict(X_test)\n",
    "y_proba = model_rf.predict_proba(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "lloss = log_loss(y_test, y_proba)\n",
    "\n",
    "print(f\"RF Accuracy: {accuracy:.2f}\")\n",
    "print(f\"RF F1 Score: {f1_macro:.2f}\")\n",
    "print(f\"RF Log Loss: {lloss:.4f}\")\n",
    "#print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 371048,
     "status": "ok",
     "timestamp": 1750051734252,
     "user": {
      "displayName": "Huỳnh Phú Sĩ",
      "userId": "14333305800252361705"
     },
     "user_tz": -420
    },
    "id": "tqgK3PsxJlhT",
    "outputId": "240df072-8790-4ed3-c9ce-a1183d59fc33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.98\n",
      "SVM F1 Score: 0.97\n",
      "SVM Log Loss: 0.1008\n"
     ]
    }
   ],
   "source": [
    "model_svm = SVC(kernel='rbf', C=1.0, probability=True, random_state=42)\n",
    "model_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_svm.predict(X_test)\n",
    "y_proba = model_svm.predict_proba(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "lloss = log_loss(y_test, y_proba)\n",
    "\n",
    "print(f\"SVM Accuracy: {accuracy:.2f}\")\n",
    "print(f\"SVM F1 Score: {f1_macro:.2f}\")\n",
    "print(f\"SVM Log Loss: {lloss:.4f}\")\n",
    "#print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23492,
     "status": "ok",
     "timestamp": 1750052370349,
     "user": {
      "displayName": "Huỳnh Phú Sĩ",
      "userId": "14333305800252361705"
     },
     "user_tz": -420
    },
    "id": "IXK-Xp6EKMvb",
    "outputId": "4cd95dcd-a10a-43d5-8b44-3f022f52966c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Accuracy: 0.97\n",
      "XGB F1 Score: 0.96\n",
      "XGB Log Loss: 0.1089\n"
     ]
    }
   ],
   "source": [
    "model_xgb = XGBClassifier(n_estimators=100, max_depth=8, min_child_weight=10, learning_rate=0.1, eval_metric='mlogloss', random_state=42)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_xgb.predict(X_test)\n",
    "y_proba = model_xgb.predict_proba(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "lloss = log_loss(y_test, y_proba)\n",
    "\n",
    "print(f\"XGB Accuracy: {accuracy:.2f}\")\n",
    "print(f\"XGB F1 Score: {f1_macro:.2f}\")\n",
    "print(f\"XGB Log Loss: {lloss:.4f}\")\n",
    "#print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRF Accuracy: 0.95715\n",
      "PRF F1 Score: 0.95\n",
      "PRF Log Loss: 0.2783\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, dX_train, dX_test, py_train, py_test = train_test_split(\n",
    "    X, dX, py, test_size=0.2, random_state=42, stratify=np.argmax(py, axis=1)\n",
    ")\n",
    "\n",
    "model_prf = prf(n_estimators=100, bootstrap=True, max_depth=8, keep_proba=0.8, n_jobs=-1)\n",
    "model_prf.fit(X=X_train, dX=dX_train, py=py_train)\n",
    "\n",
    "y_test_bin = py_test.argmax(axis=1)\n",
    "y_proba_prf = np.array(model_prf.predict_proba(X_test, dX=dX_test))\n",
    "y_pred_prf = y_proba_prf.argmax(axis=1)\n",
    "f1_macro = f1_score(y_test_bin, y_pred_prf, average='macro')\n",
    "lloss = log_loss(y_test_bin, y_proba_prf)\n",
    "\n",
    "print(\"PRF Accuracy:\", model_prf.score(X_test, dX=dX_test, y=y_test_bin))\n",
    "print(f\"PRF F1 Score: {f1_macro:.2f}\")\n",
    "print(f\"PRF Log Loss: {lloss:.4f}\")\n",
    "#print(classification_report(y_test_bin, y_pred_prf, digits=3))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPVimkiDxTc8pOp9DYsEi6a",
   "gpuType": "T4",
   "mount_file_id": "1SPA3ZbZhNWEQXUke5fgqJWFEpRVvh4kC",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
